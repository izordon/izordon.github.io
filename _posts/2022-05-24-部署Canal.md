---
layout:     post
title:      部署单机版Canal并推送数据到Kafka
subtitle:   Canal是用java开发的基于数据库增量日志解析，提供增量数据订阅&消费的中间件。
date:       2022-05-24
author:     Zordon Yang
header-img: img/post-bg-re-vs-ng2.jpg
catalog: false
tags:
    - 部署文档
    - 数据库相关
---
- [Canal](#canal)
  - [部署](#部署)
    - [1、下载Canal](#1下载canal)
    - [2、MySQL配置开启binlog](#2mysql配置开启binlog)
    - [3、binlog分类](#3binlog分类)
    - [4、binlog格式选择](#4binlog格式选择)
    - [5、MySQL配置Canal用户](#5mysql配置canal用户)
    - [6、解压Canal及conf目录结构](#6解压canal及conf目录结构)
    - [7、Canal推送数据到Kafka](#7canal推送数据到kafka)
    - [8、启动Canal并检查](#8启动canal并检查)
    - [9、检查Kafka是否接受到数据](#9检查kafka是否接受到数据)

# Canal
- Github项目地址：https://github.com/alibaba/canal

## 部署

### 1、下载Canal
- Github下载地址：https://github.com/alibaba/canal/releases
- 包名：canal.deployer-x.x.x.tar.gz

### 2、MySQL配置开启binlog
- 打开MySQL配置文件
```bash
vim /etc/my.cnf
```

- 在 **[mysqld]** 区块添加：
```yaml
log-bin=mysql-bin
server-id= 1
log-bin=mysql-bin
binlog_format=row
binlog-do-db=testdb
```

- 重启MySQL
```bash
systemctl restart mysqld
```

**到数据目录下查询是否生成binlog文件**

### 3、binlog分类
- binlog的格式有三种：STATEMENT,MIXED,ROW对比如下

| 格式 | 描述 | 优点 | |
| --- | --- | --- | --- |
| STATEMENT	| 语句级别，记录每一次执行写操作的语句，相对于ROW模式节省了空间，但是可能产生数据不一致如update tt set create_date=now()，由于执行时间不同产生得数据就不同	 |节省空间 | 可能造成数据不一致 |
| ROW	| 行级，记录每次操作后每行记录的变化。假如一个update的sql执行结果是1万行statement只存一条，如果是row的话会把这个1000行的结果存这。	| 保持数据的绝对一致性。 因为不管sql是什么，引用了什么函数，他只记录执行后的效果	| 占用较大空间 |
| MIXED	| 是对statement的升级，如当函数中包含 UUID() 时，包含 AUTO_INCREMENT 字段的表被更新时，执行 INSERT DELAYED 语句时，用 UDF 时，会按照 ROW的方式进行处理	| 节省空间，同时兼顾了一定的一致性	 | 还有些极个别情况依旧会造成不一致，另外statement和mixed对于需要对binlog的监控的情况都不方便 |

### 4、binlog格式选择
        如果只考虑主从复制的话可以用mixed，一般情况下使用statement，遇到几种特殊情况使用row，同步的话有SQL就行，因为手里有数据，前提是有数据才能执行这个SQL。在大数据场景下我们抽取数据是用于统计分析，分析的数据，如果用statement抽了SQL手里也没数据，不知道执行修改哪些，因为没有数据，所以没办法分析，所以适合用row，清清楚楚的表明了每一行是什么样。

### 5、MySQL配置Canal用户
```sql
GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%' IDENTIFIED BY 'Canal@2022' ;
```

### 6、解压Canal及conf目录结构
- 解压
```bash
tar -zxvf canal.deployer-1.1.4.tar.gz
```
- 配置说明：canal server的conf下有几个配置文件
```
conf/
├── canal_local.properties
├── canal.properties
├── example
│   ├── h2.mv.db
│   ├── instance.properties
│   └── meta.dat
├── logback.xml
├── metrics
│   └── Canal_instances_tmpl.json
└── spring
    ├── base-instance.xml
    ├── default-instance.xml
    ├── file-instance.xml
    ├── group-instance.xml
    ├── memory-instance.xml
    └── tsdb
        ├── h2-tsdb.xml
        ├── mysql-tsdb.xml
        ├── sql
        │   └── create_table.sql
        └── sql-map
            ├── sqlmap-config.xml
            ├── sqlmap_history.xml
            └── sqlmap_snapshot.xml
```

### 7、Canal推送数据到Kafka
- 修改配置文件：/canal/conf/canal.properties
```yaml
canal.serverMode = kafka    #修改拉取数据模式为kafka
```
- 修改配置文件：/canal/conf/example/instance.properties
```yaml
canal.instance.master.address=10.0.0.2:3306    #MySQL数据库地址:端口
canal.instance.master.journal.name=mysql-bin.000090    #如果需要修改为指定的binlog，修改此项
canal.instance.master.position=364148    #如果需要修改为指定的pos位置，修改此项
...
canal.instance.dbUsername = canal    #MySQL数据库的用户名
canal.instance.dbPassword = Canal@2022    #MySQL数据库的密码
...
canal.mq.topic=canal-topic    #Kafka的Topic名称
```
### 8、启动Canal并检查
- 启动Canal
```bash
bash /canal/bin/startup.sh
```
- 检查Canal是否正常运行
```bash
#检查进程
ps -ef | grep canal
#检查端口服务
netstat -nltp | grep 1111
#检查日志
tail -f /canal/logs/example/example.log
```
### 9、检查Kafka是否接受到数据
- Kafka查看topic数据